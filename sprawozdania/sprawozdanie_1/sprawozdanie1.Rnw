\documentclass[12pt]{mwart}
\usepackage[utf8]{inputenc}
\usepackage[left=2cm, right=2cm, top=2cm, bottom=2cm]{geometry}
\usepackage{listings}
\usepackage{mathtools, amsthm, amssymb, amsmath}
\usepackage[plmath]{polski}
\usepackage{hyperref}
\usepackage{enumitem}
\usepackage{rotating}
\DeclareMathOperator{\E}{\text{E}}
\DeclareMathOperator{\Var}{\text{Var}}
\date{\today}
\title{Sprawozdanie 1}
\author{Piotr Zieleń}
<<echo=F>>=
pdf.options(encoding="CP1250")
@
\begin{document}
\maketitle
\tableofcontents
\newpage

Celem sprawozdania jest przedstawienie rozwiązań oraz wniosków, gdy jest to konieczne, z rozwiązywanych podczas zajęć labolatoryjnych list zadań.
\section{Lista 1}
Zaimportowałem biblioteki konieczne do rozwiązania zadań.
<<message=F, warning=F>>=
library(vcdExtra) # w tej bibliotece
          # znajdują się dane, z których korzystamy
library(tidyverse)
@
\subsection{Zadanie 1}
W tym zadaniu należało sporządzić tabele liczności dla zmiennych \emph{Temperature} oraz \emph{Preference} biorąc pod uwagę wszystkie dane, jak również w podgrupach ze względu na zmienną \emph{Water softness}.

Kody do uzyskania wyników przedstawiłem dla zmiennej \emph{Temperature} dla wszystkich danych i dla podgrupy \emph{Soft}. W pozostałych przypadkach kody wyglądały bardzo podobnie, zmieniłem tylko zmienną, lub nazwę podgrupy.

Uzyskałem następujące wyniki:
\begin{itemize}
\item Dla zmiennej \emph{Temperature}:
\begin{itemize}[label=\(\bullet\)]
\item Dla wszystkich podgrup:
<<>>=
apply(Detergent, "Temperature", sum)
@
\item Dla podgrupy \emph{Soft}:
<<>>=
apply(Detergent[, , , "Soft"], "Temperature", sum)
@
\item Dla podgrupy \emph{Medium}:
<<echo=F>>=
apply(Detergent[, , , "Medium"], "Temperature", sum)
@
\item Dla podgrupy \emph{Hard}:
<<echo=F>>=
apply(Detergent[, , , "Hard"], "Temperature", sum)
@
\end{itemize}
\item Dla zmiennej \emph{Preference}:
\begin{itemize}[label=\(\bullet\)]
\item Dla wszystkich podgrup:
<<echo=F>>=
apply(Detergent, "Preference", sum)
@
\item Dla podgrupy \emph{Soft}:
<<echo=F>>=
apply(Detergent[, , , "Soft"], "Preference", sum)
@
\item Dla podgrupy \emph{Medium}:
<<echo=F>>=
apply(Detergent[, , , "Medium"], "Preference", sum)
@
\item Dla podgrupy \emph{Hard}:
<<echo=F>>=
apply(Detergent[, , , "Hard"], "Preference", sum)
@
\end{itemize}
\end{itemize}
\subsection{Zadanie 2}
W tym zadaniu należało sporządzić tabelę wielodzielczą, uwzględniającą zmienną \emph{Temperature} i \emph{Water Softness}.

Uzyskałem następującą tabelę:
<<>>=
structable(Temperature ~ Water_softness, Detergent)%>%
    addmargins()
@
\subsection{Zadanie 3}
W tym zadaniu należało sporządzić wykres kołowy i słupkowy dla zmiennej \emph{Water Softness}
<<Wykr_slupkowy1, fig.cap="Wykres słupkowy zmiennej Water Softness">>=
data <- apply(Detergent, "Water_softness", sum)
barplot(data, xlab="Water softness", ylab="Ilość osób",
        main="Wykres słupkowy dla zmiennej Water Softness",
        ylim=c(0, 400), col=c("red", "blue", "green"))
@

<<Wykr_kolowy1, fig.cap="Wykres kołowy zmiennej Water Softness">>=
pie(data, main="Wykres kołowy dla zmiennej Water Softness",
    col=c("red", "blue", "green"))
@
\subsection{Zadanie 4}
W tym zadaniu należało sporządzić wykresy mozaikowe, odpowiadające rozpatrywanym danym (\emph{Water Softness} i \emph{Preference}, \emph{Preference} i \emph{Temperature}, \emph{Preference} i \emph{User}) i podać krótkie wnioski do wykresu.
<<Wykr_mozaikowy1, fig.cap="Wykres mozaikowy Zmiennej Water Softnes i Preference">>=
mosaicplot(~Water_softness + Preference, data=Detergent,
           main="Wykres mozaikowy zmiennych
           Water Softness i Preference")
@
Na rysunku (\ref{fig:Wykr_mozaikowy1}) przedstawiłem wykres mozaikowy zmiennych \emph{Water Softness} i \emph{Preference}. Zmienna \emph{Water Softness} przyjmuje trzy wartości (\emph{Soft}, \emph{Medium}, \emph{Hard}), a zmienna \emph{Preference}\pauza 2 (\emph{Brand M}, \emph{Brand X}), dlatego wykres mozaikowy jest podzielony na sześć prostokątów. Na rysunku widać, że możliwe przyjmowane wartości zmiennej \emph{Water Softness} oraz zmiennej\emph{Preference}, nie różnią się bardzo, pod względem wielkości pól na wykresie, co oznacza, że wśród tych zmiennych, nie ma podzbioru, który by się wyróżniał na tle całości. Można jednak zauważyć, że w ankiecie najczęściej wybieranymi odpowiedziami dla rozważanych zmiennych, były: \emph{Medium} i \emph{Brand M}
<<Wykr_mozaikowy2, echo=F, fig.cap="Wykres mozaikowy zmiennej Preference i Temperature">>=
mosaicplot(~Preference + Temperature, Detergent,
           main="Wykres mozaikowy zmiennych Preference i Temperature")
@
Na rysunku (\ref{fig:Wykr_mozaikowy2}) przedstawiłem wykres mozaikowy zmiennych \emph{Preference} i \emph{Temperature}. Zmienna \emph{Preference} przyjmuje dwie wartości, a zmienna \emph{Temperature} (\emph{Low} i \emph{High}), więc wykres jest podzielony na cztery  prostokąty. Widać wyraźnie, że dużo częściej wybieraną w ankiecie wartością temperatury była: \emph{Low}. Z wykresu można odczytać, że najczęściej wybieranymi odpowiedziami w tej ankiecie były: \emph{Low} i \emph{Brand X}, natomiast najrzadziej: \emph{High} i \emph{Brand X}.
<<Wykr_mozaikowy3, echo=F, fig.cap="Wykres mozaikowy Zmiennej Preference i M User">>=
mosaicplot(~Preference + M_User, Detergent,
           main="Wykres mozaikowy zmiennych Preference i M_User")
@
Na rysunku (\ref{fig:Wykr_mozaikowy3}) przedstawiłem wykres mozaikowy zmiennych \emph{Preference} i \emph{M\_User}. Zmienna \emph{Preference} przyjmuje dwie wartości, podobnie jak zmienna \emph{M\_User} (\emph{Yes} i \emph{No}), więc wykres jest podzielony na cztery prostokąty. Na wykresie widać, że wartości zmiennej \emph{M\_User} dość znacząco różnią się w zależności od przyjmowanych wartości zmiennej \emph{Preference}. Najczęstszymi odpowiedziami, w tej ankiecie, wśród rozważanych zmiennych, były: \emph{Brand X} oraz \emph{No}, natomiast najrzadziej: \emph{Brand X} i \emph{Yes}.
\section{Lista 2}
Zaimportowałem bibliotekę, która przydała się do sprawdzenia wariancji w zadaniu 3. \pauza podrozdział (\ref{section:zadanie_3})
<<message=F, warning=F>>=
library("matrixStats")
@
\subsection{Zadanie 1}
Aby zrobić to zadanie, skorzystałem z danych \verb|mtcars|.
<<>>=
data <- mtcars
data
@

Celem zadania jest napisanie fragmentu programu, którego celem jest wylosowanie próbki rozmiaru około 1/10 liczby przypadków z wybranej bazy danych ze zwracaniem i bez zwracania.

\subsubsection{Dla przypadku ze zwracaniem}
W pierwszym kroku wylosowałem numery wierszy dla których odczytamy dane:
<<>>=
ind <- sample(nrow(mtcars), 0.1*nrow(mtcars), replace=T)
ind
@
Następnie odczytałem dane dla wylosowanych numerów wierszy
<<>>=
mtcars[ind, ]
@
\subsubsection{Dla przypadku bez zwracania}
W celu wyznaczenia numerów wierszy bez zwracania, wystarczy zmienić argument \verb|replace| funkcji \verb|sample| z wartości \verb|TRUE| na \verb|FALSE|.
<<>>=
ind <- sample(nrow(mtcars), 0.1*nrow(mtcars), replace=F)
ind
@
<<>>=
mtcars[ind, ]
@
\subsection{Zadanie 2}
W tym zadaniu należało zaproponować algorytm generowania wektora z rozkładu dwumianowego i sprawdzić jego poprawność oraz napisać program do generowania tych liczb, zgodnie z zaproponowanym algorytmem i sprawdzić czy zaproponowany algorytm działa poprawnie, na podstawie porównania wartości oczekiwanej i wariancji wysymulowanych prób do teoretycznej wartości oczekiwanej i wariancji. Przypominając, jeśli \(X\sim\mathcal B(n, p)\), to:
\begin{gather}
	\E{X} = np\\
	\Var{X} = np(1-p)
\end{gather}
\subsubsection{Pierwszy algorytm}
Chcemy wygenerować zmienną losową \(X\) z rozkładu dwumianowego (\(X\sim\mathcal B(n, p)\)). Dla zmiennej losowej \(Y\) dyskretnej, zdefiniowanej następująco:
\begin{align}
P(Y_i=1)&=p\\
P(Y_i=0)&=1-p\\
p\in[0, 1]
\end{align}
Zmienna losowa \(X\) będzie równa co do rozkładu sumie niezależnych zmiennych losowych \(Y_i\) (\(X\stackrel{\text{d}}=\displaystyle{\sum_{i=1}^nY_i}, Y_i\)\pauza i.i.d.).
Korzystając z tego faktu można zaproponować następujący algorytm:
\begin{enumerate}
\item Losujemy \(U\sim \mathcal{U}(0, 1)\)
\item Jeżeli \(U<p\), to \(Y\)=1, w przeciwnym wypadku \(Y=0\)
\item Powtarzamy ktoki 1 i 2 \(n\) razy
\item Wstawiamy \(X=\displaystyle{\sum_{i=1}^nY_i}\)
\end{enumerate}

Zaproponowany program:
<<>>=
binom.rv <- function(n, p, N){
    sapply(1:N, function(...){
        sum(runif(n) < p)
    })
}
@
Sprawdźmy teraz poprawność zaproponowanego kodu:
<<>>=
Y1 <- binom.rv(10, 0.4, 1000) # Rozkład B(10, 4)
mean(Y1) # Wartość oczekiwana teoretyczna: 4
var(Y1) # Wariancja teoretyczna: 2.4

Y2 <- binom.rv(50, 0.2, 1000) # Rozkład B(50, 0.2)
mean(Y2) # Wartość oczekiwana teoretyczna: 10
var(Y2) # Wariancja teoretyczna: 8

Y3 <- binom.rv(100, 0.6, 1000) # Rozkład B(100, 0.6)
mean(Y3) # Wartość oczekiwana teoretyczna: 60
var(Y3) # Wariancja teoretyczna 24
@
Widać, że zaproponowana metoda sprawdza się całkiem dobrze. Wartości oczekiwane i wariancje dla przykładowych trzech prób, są bliskie wartości oczekiwanej i wariancji teoretycznej.
\subsubsection{Drugi algorytm}
W drugim algorytmie skupiłem się na sposobie generowania zmiennej losowej dyskretnej, metodą akceptacji{\dywiz}odrzucenia. Celem jest wyznaczenie zmiennej losowej \(X\sim\mathcal{B}(n, p)\) W tej metodzie mamy dwa założenia:
\begin{enumerate}
\item potrafimy efektywnie generować inną zmienną losową \(Y\), o rozkładzie: \(q_i=P(Y=i)\), tak aby zmienne losowe \(X\) i \(Y\) przyjmowały wartości z tego samego zbioru
\item potrafimy wyznaczyć stałą \(0<c<\infty\), taką że \(\max\frac{p_i}{q_i}\leq c\)
\end{enumerate}
Algorytm:
\begin{enumerate}
\item Generuj jedną realizację zmiennej losowej \(Y\)
\item Generuj \(U\sim\mathcal{U}(0, 1), \quad U\perp Y\)
\item Jeśli \(U\leq\frac{p_Y}{cq_Y}\), to zwróć \(X=Y\), w przeciwnym wypadku wróć do 1.
\end{enumerate}
W celu napisania programu, wprowadziłem funkcję pomocniczą \verb|pY|, która wyznacza wartość \(p_Y\):
<<>>=
pY <- function(Y, p){
    if (Y == 1){
        p
    } else {
        1-p
    }
}
@
Zaproponowany program:
<<>>=
binom.rv2 <- function(n, p, N){
    sapply(1:N, function(...){
        a <- c()
        for (i in 1:n){
            while (length(a) != n){
                Y <- round(runif(1))
                c <- 2
                U <- runif(1)
                if (U <= pY(Y, p)/(c*0.5)){
                    a <- append(a, Y)
                }
            }
        }
        sum(a)
    })
}
@
Sprawdźmy teraz poprawność zaproponowanego kodu:
<<>>=
Y4 <- binom.rv2(10, 0.4, 1000)
			# Rozkład B(10, 4)
mean(Y4) # Wartość oczekiwana teoretyczna: 4
var(Y4) # Wariancja teoretyczna: 2.4

Y5 <- binom.rv2(50, 0.2, 1000)
			# Rozkład B(50, 0.2)
mean(Y5) # Wartość oczekiwana teoretyczna: 10
var(Y5) # Wariancja teoretyczna: 8

Y6 <- binom.rv2(100, 0.6, 1000)
			# Rozkład B(100, 0.6)
mean(Y6) # Wartość oczekiwana teoretyczna: 60
var(Y6) # Wariancja teoretyczna 24
@
Na podstawie uzyskanych symulacyjnie wyników, możemy stwierdzić, że zaproponowany algorytm działa całkiem dobrze. Wartości \(\E{X}\) i \(\Var{X}\) wyznaczonych symulacyjnie prób, są bliskie teoretycznym wartością \(\E{X}\) i \(\Var{X}\).
\subsection{Zadanie 3}\label{section:zadanie_3}
W tym zadaniu należało zaproponować algorytm generowania wektora z rozkładu wielomianowego i udowodnić jego poprawność, na podstawie wysymulowanej wielokrotnie próby i porównania jej średniej wartości oczekiwanej i wariancji z teoretyczną wartością oczekiwaną i wariancją oraz napisać program do generowania tych wektorów, zgodnie z zaproponowanym algorytmem.
\subsubsection{Pierwszy algorytm}
Zaproponowany algorytm wygląda następująco:
\begin{enumerate}
	\item Zadeklaruj pusty wektor \(X\), o długości \(k\) (liczba odpowiedzi na pytanie w ankiecie), składający się z samych zer
	\item Generuj indeks \(I\), \(P(I=i)=p_i, i=1,\dots,k\)
	\item Wstaw \(X[I] = X[I] + 1\)
	\item Powtórz kroki 1\ppauza3, \(n\) razy
\end{enumerate}
<<>>=
multinom.rv <- function(n, p, N=1) {
 sapply(1:N, function(...){
  k <- length(p)
  X <- numeric(k)
  I <- sample(x=1:k, size=n, replace = TRUE, prob = p)
   for (i in 1:n) {
   X[I[i]] = X[I[i]] + 1
   }
  X
  }
 )
}
@
Do sprawdzenia wariancji, będziemy potrzebować funkcji \verb|rowVars| z zaimportowanej biblioteki \verb|‘matrixStats’|
Zobaczmy teraz czy zaproponowany kod działa poprawnie:
<<>>=
Y7 <- multinom.rv(10, c(0.5,0.1,0.4), 1000)
			# Rozkład B(10, 4)
rowMeans(Y7) # Wartość oczekiwana teoretyczna: (5, 1, 4)
rowVars(Y7) # Wariancja teoretyczna: (2.5, 0.9, 2.4)

Y8 <- multinom.rv(50, c(0.25,0.45,0.3), 1000)
			# Rozkład B(50, 0.2)
rowMeans(Y8) # Wartość oczekiwana teoretyczna: (12.5, 22.5, 15)
rowVars(Y8) # Wariancja teoretyczna: (9.375, 12,375, 10.5)

Y9 <- multinom.rv(100, c(0.3,0.4,0.3), 1000)
			# Rozkład B(100, 0.6)
rowMeans(Y9) # Wartość oczekiwana teoretyczna: (30, 40, 30)
rowVars(Y9) # Wariancja teoretyczna: (21, 24, 21)
@
\subsubsection{Drugi algorytm}
Drugie podejście jest podobne do pierwszego, natomiast jest kilka różnic. Prawdopodobieństwo uzyskania każdej odpowiedzi na pytanie w ankiecie możemy umieścić na pewnym przedziale, na odcinku \([0, 1]\). Wtedy na podstawie wygenerowanej zmiennej losowej z rozkładu jednostajnego na odcinku \([0, 1]\), możemy podać odpowiedź, która padła na pytanie.

Zaproponowany algorytm:
\begin{enumerate}
	\item Zadeklaruj pusty wektor \(X\), o długości \(k\) (liczba odpowiedzi na pytanie w ankiecie), składający się z samych zer
	\item Generuj \(U\sim U(0, 1)\)
	\item Wstaw \(I = 1\) \(P = p_1\) (prawdopodobieństwo uzyskania na przykład pierwszej odpowiedzi w ankiecie)
	\item Jeśli \(U > P\) to wstaw \(I = I + 1\) i \(P = P + p_I\), w przeciwnym wypadku powtórz krok.
	\item Wstaw X[i] = X[i] + 1
	\item Powtórz kroki 2{\ppauza}5 \(n\) razy.
\end{enumerate}
Kod do zaproponowanego algorytmu:
<<>>=
multinom.rv2 <- function(n, p, N){
  sapply(1:N, function(...){
    vect <- numeric(length(p))
    for (j in 1:n){
    U <- runif(1)
    P <- p[1]
    i <- 1
    while (U > P) {
      i <- i + 1
      P <- P + p[i]
    }
    vect[i] <- vect[i] + 1
    }
  vect
  })
}
@
Sprawdźmy poprawność działania kodu:
<<>>=
Y10 <- multinom.rv2(10, c(0.5,0.1,0.4), 1000)
			# Rozkład B(10, 4)
rowMeans(Y10) # Wartość oczekiwana teoretyczna: (5, 1, 4)
rowVars(Y10) # Wariancja teoretyczna: (2.5, 0.9, 2.4)

Y11 <- multinom.rv2(50, c(0.25,0.45,0.3), 1000)
			# Rozkład B(50, 0.2)
rowMeans(Y11) # Wartość oczekiwana teoretyczna: (12.5, 22.5, 15)
rowVars(Y11) # Wariancja teoretyczna: (9.375, 12,375, 10.5)

Y12 <- multinom.rv2(100, c(0.3,0.4,0.3), 1000)
			# Rozkład B(100, 0.6)
rowMeans(Y12) # Wartość oczekiwana teoretyczna: (30, 40, 30)
rowVars(Y12) # Wariancja teoretyczna: (21, 24, 21)
@
Na podstawie uzyskanych wyników, można stwierdzić, że zaproponowany algorytm działa poprawnie.
\subsection{Zadanie 4}
Zadanie polega na stworzeniu propozycji badania ankietowego. \newline

\textbf{Cel badania:} Czy zwiększyły się preferencje dotyczące dań wegeteriańskich i wegańskich wśród studentów i pracowników? Celem badania ankietowego jest sprawdzenie preferencji żywieniowych i stworzenie na tej podstawie odpowiedniego menu w stołówce studenckiej PWr. \newline

\textbf{Grupa docelowa:} Studenci i pracownicy PWr. \newline 

\textbf{Sposób zbierania danych:} Ankieta zostałaby prowadzona online w celu łatwiejszego dostępu do analizowanych danych. Studenci przy zamawianiu obiadu proszeni byliby o zeskanowanie kodu QR z linkiem do ankiety, oprócz tego również zostałyby wysłane maile. Wykorzystanym schematem losowania byłoby losowanie warstwowe. Wyodrębnione warstwy to przede wszystkim osobno grupa studentów i grupa pracowników, ale można byłoby podzielić również bardziej dokładnie na mniejsze przedziały wiekowe oraz ze względu na płeć. \newline 

Ankieta zawierać będzie   pytań z odpowiedziami w 5-stopniowej skali oraz metryczkę. \newline 

\textbf{Propozycja kwestionariusza:} \newline 

Metryczka:
\begin{enumerate}
\item Student/Pracownik:
\item Płeć:
\item Wiek:
\item Rok studiów/Rok pracy na uczelni:
\item Wydział:
\end{enumerate}

Pytania:
\begin{enumerate}
\item Jak często korzystasz z posiłków w SKS-ie?
  \begin{enumerate}
  \item bardzo rzadko
  \item rzadko 
  \item czasem 
  \item często
  \item bardzo często \newline
  \end{enumerate}
\item Jak często wybierasz opcję bezmięsną w SKS-ie?
\begin{enumerate}
  \item bardzo rzadko
  \item rzadko 
  \item czasem 
  \item często
  \item bardzo często \newline
  \end{enumerate}
\item Czy chciałbyś, chciałabyś, aby została zwiększona liczba dań wegetariańskich?
\begin{enumerate}
  \item zdecydowanie nie
  \item nie 
  \item nie wiem 
  \item tak 
  \item zdecydowanie tak \newline
  \end{enumerate}
\item Czy korzystałbyś z oferty posiłków wegańskich?
\begin{enumerate}
  \item zdecydowanie nie
  \item nie 
  \item nie wiem 
  \item tak 
  \item zdecydowanie tak \newline
  \end{enumerate}
\end{enumerate}

\textbf{Wyniki:} Wyniki zostałyby przedstawione w tabelach oraz na wykresach słupkowych. 

\section{Lista 3}
Zaimportowałem biblioteki, które przydadzą się do rozwiązywanych zadań:
<<message=F, warning=F>>=
library(binom)
library(stats)
@
\subsection{Zadanie 1}\label{section:zadanie_1}
W tym zadaniu należało przeprowadzić symulację, w celu porównania prawdopodobieństwa pokrycia i długości przedziałów ufności Cloppera{\dywiz}Pearsona (exact), Walda (asymptotic) i dowolnego wybranego typu przedziału ufności, zaimplementowanego w funkcji \emph{binom.confint}.\newline
Należało przyjąć poziom ufności \pauza 0.95, różne rozmiary próby i różne wartości prawdopodobieństwa \(p\) oraz wyniki umieścić na rysunkach i w tabelach i wyciągnąć wnioski.

Jako dowolny przedział ufności, wziąłęm przedziay Agrestiego{\dywiz}Coulla. Przedział ten jest przedziałem ufności punktowo asymptotycznym. Wprowadzając oznaczenia:
\begin{gather}
\kappa(\alpha)=z\left(1-\frac{\alpha}{2}\right)\\
\tilde X=\displaystyle{\sum_{i=1}^nX_i+\frac{\kappa^2(\alpha)}{2}}\\
\tilde n=n+\kappa^2(\alpha)\\
\tilde p=\frac{\tilde X}{\tilde n}\\
\tilde q=1-\tilde p
\end{gather}
gdzie \(z\) to dystrybuanta rozkładu \(\mathcal N(0, 1)\), przedziały ufności Agrestiego{\dywiz}Coulla są postaci \([T_L^{AC}, T_U^{AC}]\), gdzie:
\begin{gather}
T_L^{AC}=\tilde p-\kappa(\alpha)(\tilde p \tilde q)^{\frac{1}{2}}\tilde n^{-\frac{1}{2}}\\
T_U^{AC}=\tilde p+\kappa(\alpha)(\tilde p \tilde q)^{\frac{1}{2}}\tilde n^{-\frac{1}{2}}
\end{gather}

Aby porównać prawdopodobieństwa pokrycia i długości rozważanych przedziałów ufności posłużyłem się symulacją Monte{\dywiz}Carlo. W tym celu napisałem funkcje:
<<>>=
funkcja <- function(N, s, p, method){
  X <- rbinom(N, s, p)
  pr_ufnosci <- binom.confint(X, s, methods=method)
  czy_p_w_pr_ufnosci <-ifelse(pr_ufnosci$lower < p
  				& pr_ufnosci$upper > p, 1, 0)
  dl_p_uf <- pr_ufnosci$upper - pr_ufnosci$lower
  c(mean(czy_p_w_pr_ufnosci), mean(dl_p_uf))
}

dane_do_wykresow <- function(MC, n, pokrycie_dl_przedzialu){
  p <- seq(0, 1, by=0.01)
  metody <- c("asymptotic", "exact", "agresti-coull")
  wyniki <- matrix(0, 3, length(p))
  for (i in 1:3){
    wyniki[i, ] <- sapply(1:length(p), function(j){
      funkcja(MC, n, p[j], metody[i])[pokrycie_dl_przedzialu]})
  }
  wyniki
}
@

<<>>=
p <- seq(0, 1, by=0.01)
rozmiary_proby <- c(10, 20, 50, 100)
MC <- 100000
@

<<prawd_pokr_n10, cache=T, fig.cap="Prawdopodobieństwa pokrycia rozważanych przedziałów ufności, dla n=10">>=
dane <- dane_do_wykresow(MC,rozmiary_proby[1], 1)

plot(p, dane[1, ], type="l", col="red",
   main="Prawdopodobieńswa pokrycia dla n=10",
   xlab = "Prawdopodobieństwo",
   ylab = "Proceny pokrycia", lwd=1)
lines(p, dane[2, ], type="l", col="green", lwd=1)
lines(p, dane[3, ], type="l", col="blue", lwd=1)
legend("bottom", legend = c("asymptotic",
                          "exact", "agresti-coull"),
     lwd=1,col=c("red", "green", "blue"))
grid()
@

<<prawd_pokr_n20, cache=T, echo=F, fig.cap="Prawdopodobieństwa pokrycia rozważanych przedziałów ufności, dla n=20">>=
dane <- dane_do_wykresow(MC,rozmiary_proby[2], 1)

plot(p, dane[1, ], type="l", col="red",
main="Prawdopodobieńswa pokrycia dla n=20",
xlab = "Prawdopodobieństwo",
ylab = "Proceny pokrycia", lwd=1)
lines(p, dane[2, ], type="l", col="green", lwd=1)
lines(p, dane[3, ], type="l", col="blue", lwd=1)
legend("bottom", legend = c("asymptotic",
"exact", "agresti-coull"),
lwd=1,col=c("red", "green", "blue"))
grid()
@

<<prawd_pokr_n50, cache=T, echo=F, fig.cap="Prawdopodobieństwa pokrycia rozważanych przedziałów ufności, dla n=50">>=
dane <- dane_do_wykresow(MC,rozmiary_proby[3], 1)

plot(p, dane[1, ], type="l", col="red",
main="Prawdopodobieńswa pokrycia dla n=50",
xlab = "Prawdopodobieństwo",
ylab = "Proceny pokrycia", lwd=1)
lines(p, dane[2, ], type="l", col="green", lwd=1)
lines(p, dane[3, ], type="l", col="blue", lwd=1)
legend("bottom", legend = c("asymptotic",
"exact", "agresti-coull"),
lwd=1,col=c("red", "green", "blue"))
grid()
@

<<prawd_pokr_n100, cache=T, echo=F, fig.cap="Prawdopodobieństwa pokrycia rozważanych przedziałów ufności, dla n=100">>=
dane <- dane_do_wykresow(MC,rozmiary_proby[4], 1)

plot(p, dane[1, ], type="l", col="red",
main="Prawdopodobieńswa pokrycia dla n=100",
xlab = "Prawdopodobieństwo",
ylab = "Proceny pokrycia", lwd=1)
lines(p, dane[2, ], type="l", col="green", lwd=1)
lines(p, dane[3, ], type="l", col="blue", lwd=1)
legend("bottom", legend = c("asymptotic",
"exact", "agresti-coull"),
lwd=1,col=c("red", "green", "blue"))
grid()
@

Na rysunkach (\ref{fig:prawd_pokr_n10}), (\ref{fig:prawd_pokr_n20}), (\ref{fig:prawd_pokr_n50}) i (\ref{fig:prawd_pokr_n100}) przedstawiłem wykresy prawdopodobieństwa pokrycia dla rozważanych przedziałów ufności, dla odpowiednio \(n=10\), \(n=20\), \(n=50\) i \(n=100\) rozmiarów próby. Wykresy powstały na podstawie symulacji Monte{\dywiz}Carlo, dla \Sexpr{MC} powtórzeń. 

Wnioski jakie można wyciągnąć na podstawie wykresów są takie, że im mniejsza próba, tym mniejszy procent pokrycia. Szczególnie taki wynik możemy zaobserwować dla skrajnych wartości. W zestawieniu trzech typów przedziałów ufności najsłabiej wypadają przedziały Walda, czyli asymptotyczne. Nawet przy zwiększaniu próby znacząco odstają od przedziałów Cloppera{\dywiz}Pearsona i Agrestiego{\dywiz}Coulla. Te dwa pozostałe typy przedziałów wypadają bardzo porównywalnie. 

<<dł_przedzialu_n10, cache=T, fig.cap="Długości przedziałów ufności rozważanych testów, dla n=10">>=
dane <- dane_do_wykresow(MC, rozmiary_proby[1], 2)

plot(p, dane[1, ], type="l", col="red",
   main="Długości przedziałów dla n=10",
   xlab = "Prawdopodobieństwo",
   ylab = "Długość przedziału", lwd=1)
lines(p, dane[2, ], type="l", col="green", lwd=1)
lines(p, dane[3, ], type="l", col="blue", lwd=1)
legend("bottom", legend = c("asymptotic",
                          "exact", "agresti-coull"),
     lwd=1,col=c("red", "green", "blue"))
grid()
@

<<dł_przedzialu_n20, cache=T, echo=F, fig.cap="Długości przedziałów ufności rozważanych testów, dla n=20">>=
dane <- dane_do_wykresow(MC, rozmiary_proby[2], 2)

plot(p, dane[1, ], type="l", col="red",
main="Długości przedziałów dla n=20",
xlab = "Prawdopodobieństwo",
ylab = "Długość przedziału", lwd=1)
lines(p, dane[2, ], type="l", col="green", lwd=1)
lines(p, dane[3, ], type="l", col="blue", lwd=1)
legend("bottom", legend = c("asymptotic",
"exact", "agresti-coull"),
lwd=1,col=c("red", "green", "blue"))
grid()
@

<<dł_przedzialu_n50, cache=T, echo=F, fig.cap="Długości przedziałów ufności rozważanych testów, dla n=50">>=
dane <- dane_do_wykresow(MC, rozmiary_proby[3], 2)

plot(p, dane[1, ], type="l", col="red",
main="Długości przedziałów dla n=50",
xlab = "Prawdopodobieństwo",
ylab = "Długość przedziału", lwd=1)
lines(p, dane[2, ], type="l", col="green", lwd=1)
lines(p, dane[3, ], type="l", col="blue", lwd=1)
legend("bottom", legend = c("asymptotic",
"exact", "agresti-coull"),
lwd=1,col=c("red", "green", "blue"))
grid()
@

<<dł_przedzialu_n100, cache=T, echo=F, fig.cap="Długości przedziałów ufności rozważanych testów, dla n=100">>=
dane <- dane_do_wykresow(MC, rozmiary_proby[4], 2)

plot(p, dane[1, ], type="l", col="red",
main="Długości przedziałów dla n=100",
xlab = "Prawdopodobieństwo",
ylab = "Długość przedziału", lwd=1)
lines(p, dane[2, ], type="l", col="green", lwd=1)
lines(p, dane[3, ], type="l", col="blue", lwd=1)
legend("bottom", legend = c("asymptotic",
"exact", "agresti-coull"),
lwd=1,col=c("red", "green", "blue"))
grid()
@
Na rysunkach (\ref{fig:dł_przedzialu_n10}), (\ref{fig:dł_przedzialu_n20}), (\ref{fig:dł_przedzialu_n50}) i (\ref{fig:dł_przedzialu_n100}) przedstawiłem wykresy długości przedziałów dla odpowiednio \(n=10\),\(n=20\), \(n=50\) i \(n=100\) rozmiarów próby. Wykresy powstały na podstawie symulacji Monte{\dywiz}Carlo, dla \Sexpr{MC} powtórzeń. 

Im większa próba tym wyniki dla trzech typów przedziałów są bardziej zbliżone. 
Większe różnice można zaobserwować dla mniejszych prób, tam zdecydowanie lepiej od innych typów wypadają przedziały Agrestiego{\dywiz}Coulla, ponieważ są krótsze. Nie dotyczy to wartości skrajnych, ale wówczas, mimo że asymptotyczne przedziały są krótsze, to ich procent pokrycia nie jest wystarczający, by brać je pod uwagę.   

\subsection{Zadanie 2}
W tym zadaniu należało wyznaczyć realizacje przedziałów ufności, na poziomie ufności \(\alpha=0.95\), dla czterech różnych zadanych prawdopodobieństw stosowania leków (w zadanym przedziale wiekowym, lub dla wszystkich osób biorących udział w ankiecie).

Dane do zadania przedstawia tabela (\ref{tab:tabela1})
\begin{table}[h!]
	\begin{center}
		\begin{tabular}{ccccc}
			\hline
			& \multicolumn{2}{c}{Wiek ankietowanych} & & \\\hline
			Lek & do lat 35 & od 36 do 55 & powyżej 55 & Suma \\\hline
			Ibuprom & 35 & 0 & 0 & 35 \\
			Apap & 22 & 22 & 0 & 44 \\
			Paracetamol & 15 & 15 & 15 & 45 \\
			Ibuprofen & 0 & 40 & 10 & 50 \\
			Panadol & 18 & 3 & 5 & 26 \\\hline
			Suma & 90 & 80 & 30 & 200 \\\hline
		\end{tabular}
	\end{center}
	\caption{Dane do zadania}
	\label{tab:tabela1}
\end{table}
\begin{itemize}[label=\(\bullet\)]
	\item W pierwszym podpunkcie należało wyznaczyć przedziały ufności, dla prawdopodobieństwa stosowania leku ibuprofen (bez względu na grupę wiekową). Odczytując z tabeli (\ref{tab:tabela1}) mamy: \(x=50\), \(n=200\).
	<<>>=
	x1 <- 50
	n1 <- 200
	data1 <- binom.confint(x1, n1)
	df <- data.frame(data1)
	df
	@
	\item Następnie należało wyznaczyć przedziały ufności, również dla leku ibuprofen, dla klientów do 35 lat. Odczytując z tabeli (\ref{tab:tabela1}) mamy: \(x=0\), \(n=90\)
	<<>>=
	x2 <- 0
	n2 <- 90
	data2 <- binom.confint(x2, n2)
	df <- data.frame(data2)
	df
	@
	\item W kolejnym podpunkcie należało wyznaczyć przedziału ufności dla prawdopodobieństwa stosowania leku apap, dla wszystkich biorących udział w ankiecie. Odczytując z tabeli (\ref{tab:tabela1}) mamy: \(x=44\), \(n=200\)
	<<>>=
	x3 <- 44
	n3 <- 200
	data3 <- binom.confint(x3, n3)
	df <- data.frame(data3)
	df
	@
	\item W ostatnim podpunkcie należało wyznaczyć przedziały ufności, podobnie jak w podpunkcie powyżej, dla prawdopodobieństwa stosowania leku apap, ale dla podgrupy do 35 lat. Odczytując z tabeli (\ref{tab:tabela1}) mamy: \(x=22\), \(n=90\)
	<<>>=
	x4 <- 22
	n4 <- 90
	data4 <- binom.confint(x4, n4)
	df <- data.frame(data4)
	df
	@
\end{itemize}
	W tabeli (\ref{tab:tabela2}) umieściłem wyniki dla testów, których użyłem w zadaniu~1 (\ref{section:zadanie_1}), a w tabelach (\ref{tab:tabela3}) i (\ref{tab:tabela4}) pozostałe przedziały ufności, które były dostępne w pakiecie \verb|binom.confint|:
\begin{sidewaystable}
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			\multicolumn{5}{|c|}{Przedziały ufności Agrestiego-Coulla} \\\hline
			Lek & Liczba sukcesów & Liczba prób & Przedział ufności & Długość przedziału \\\hline
			Ibuprofen & \Sexpr{x1} & \Sexpr{n1} & [\Sexpr{data1[1, 5]}, \Sexpr{data1[1, 6]}] &\Sexpr{data1[1, 6] - data1[1, 5]} \\\hline
			Ibuprofen (do lat 35) & \Sexpr{x2} & \Sexpr{n2} & [\Sexpr{data2[1, 5]}, \Sexpr{data2[1, 6]}] &\Sexpr{data2[1, 6] - data2[1, 5]} \\\hline
			Apap & \Sexpr{x3} & \Sexpr{n3} & [\Sexpr{data3[1, 5]}, \Sexpr{data3[1, 6]}] &\Sexpr{data3[1, 6] - data3[1, 5]} \\\hline
			Apap (do lat 35) & \Sexpr{x4} & \Sexpr{n4} & [\Sexpr{data4[1, 5]}, \Sexpr{data4[1, 6]}] &\Sexpr{data4[1, 6] - data4[1, 5]} \\\hline
			\multicolumn{5}{|c|}{Przedziały ufności Walda} \\\hline
			Ibuprofen & \Sexpr{x1} & \Sexpr{n1} & [\Sexpr{data1[2, 5]}, \Sexpr{data1[2, 6]}] &\Sexpr{data1[2, 6] - data1[2, 5]} \\\hline
			Ibuprofen (do lat 35) & \Sexpr{x2} & \Sexpr{n2} & [\Sexpr{data2[2, 5]}, \Sexpr{data2[2, 6]}] &\Sexpr{data2[2, 6] - data2[2, 5]} \\\hline
			Apap & \Sexpr{x3} & \Sexpr{n3} & [\Sexpr{data3[2, 5]}, \Sexpr{data3[2, 6]}] &\Sexpr{data3[2, 6] - data3[2, 5]} \\\hline
			Apap (do lat 35) & \Sexpr{x4} & \Sexpr{n4} & [\Sexpr{data4[2, 5]}, \Sexpr{data4[2, 6]}] &\Sexpr{data4[2, 6] - data4[2, 5]} \\\hline
			\multicolumn{5}{|c|}{Przedziały ufności Cloppera{\dywiz}Pearsona} \\\hline
			Ibuprofen & \Sexpr{x1} & \Sexpr{n1} & [\Sexpr{data1[5, 5]}, \Sexpr{data1[5, 6]}] &\Sexpr{data1[5, 6] - data1[5, 5]} \\\hline
			Ibuprofen (do lat 35) & \Sexpr{x2} & \Sexpr{n2} & [\Sexpr{data2[5, 5]}, \Sexpr{data2[5, 6]}] &\Sexpr{data2[5, 6] - data2[5, 5]} \\\hline
			Apap & \Sexpr{x3} & \Sexpr{n3} & [\Sexpr{data3[5, 5]}, \Sexpr{data3[5, 6]}] &\Sexpr{data3[5, 6] - data3[5, 5]} \\\hline
			Apap (do lat 35) & \Sexpr{x4} & \Sexpr{n4} & [\Sexpr{data4[5, 5]}, \Sexpr{data4[5, 6]}] &\Sexpr{data4[5, 6] - data4[5, 5]} \\\hline
		\end{tabular}
	\end{center}
	\caption{Uzyskane wyniki dla przedziałów wykorzystanych w zadaniu 1.}
	\label{tab:tabela2}
\end{sidewaystable}
\begin{sidewaystable}
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			\multicolumn{5}{|c|}{Przedziały ufności Bayesa} \\\hline
			Lek & Liczba sukcesów & Liczba prób & Przedział ufności & Długość przedziału \\\hline
			Ibuprofen & \Sexpr{x1} & \Sexpr{n1} & [\Sexpr{data1[3, 5]}, \Sexpr{data1[3, 6]}] &\Sexpr{data1[3, 6] - data1[3, 5]} \\\hline
			Ibuprofen (do lat 35) & \Sexpr{x2} & \Sexpr{n2} & [\Sexpr{data2[3, 5]}, \Sexpr{data2[3, 6]}] &\Sexpr{data2[3, 6] - data2[3, 5]} \\\hline
			Apap & \Sexpr{x3} & \Sexpr{n3} & [\Sexpr{data3[3, 5]}, \Sexpr{data3[3, 6]}] &\Sexpr{data3[3, 6] - data3[3, 5]} \\\hline
			Apap (do lat 35) & \Sexpr{x4} & \Sexpr{n4} & [\Sexpr{data4[3, 5]}, \Sexpr{data4[3, 6]}] &\Sexpr{data4[3, 6] - data4[3, 5]} \\\hline
			\multicolumn{5}{|c|}{Przedziały ufności Cloglog} \\\hline
			Ibuprofen & \Sexpr{x1} & \Sexpr{n1} & [\Sexpr{data1[4, 5]}, \Sexpr{data1[4, 6]}] &\Sexpr{data1[4, 6] - data1[4, 5]} \\\hline
			Ibuprofen (do lat 35) & \Sexpr{x2} & \Sexpr{n2} & [\Sexpr{data2[4, 5]}, \Sexpr{data2[4, 6]}] &\Sexpr{data2[4, 6] - data2[4, 5]} \\\hline
			Apap & \Sexpr{x3} & \Sexpr{n3} & [\Sexpr{data3[4, 5]}, \Sexpr{data3[4, 6]}] &\Sexpr{data3[4, 6] - data3[4, 5]} \\\hline
			Apap (do lat 35) & \Sexpr{x4} & \Sexpr{n4} & [\Sexpr{data4[4, 5]}, \Sexpr{data4[4, 6]}] &\Sexpr{data4[4, 6] - data4[4, 5]} \\\hline
			\multicolumn{5}{|c|}{Przedziały ufności Logit} \\\hline
			Ibuprofen & \Sexpr{x1} & \Sexpr{n1} & [\Sexpr{data1[6, 5]}, \Sexpr{data1[6, 6]}] &\Sexpr{data1[6, 6] - data1[6, 5]} \\\hline
			Ibuprofen (do lat 35) & \Sexpr{x2} & \Sexpr{n2} & [\Sexpr{data2[6, 5]}, \Sexpr{data2[6, 6]}] &\Sexpr{data2[6, 6] - data2[6, 5]} \\\hline
			Apap & \Sexpr{x3} & \Sexpr{n3} & [\Sexpr{data3[6, 5]}, \Sexpr{data3[6, 6]}] &\Sexpr{data3[6, 6] - data3[6, 5]} \\\hline
			Apap (do lat 35) & \Sexpr{x4} & \Sexpr{n4} & [\Sexpr{data4[6, 5]}, \Sexpr{data4[6, 6]}] &\Sexpr{data4[6, 6] - data4[6, 5]} \\\hline
			\multicolumn{5}{|c|}{Przedziały ufności Probit} \\\hline
			Ibuprofen & \Sexpr{x1} & \Sexpr{n1} & [\Sexpr{data1[7, 5]}, \Sexpr{data1[7, 6]}] &\Sexpr{data1[7, 6] - data1[7, 5]} \\\hline
			Ibuprofen (do lat 35) & \Sexpr{x2} & \Sexpr{n2} & [\Sexpr{data2[7, 5]}, \Sexpr{data2[7, 6]}] &\Sexpr{data2[7, 6] - data2[7, 5]} \\\hline
			Apap & \Sexpr{x3} & \Sexpr{n3} & [\Sexpr{data3[7, 5]}, \Sexpr{data3[7, 6]}] &\Sexpr{data3[7, 6] - data3[6, 5]} \\\hline
			Apap (do lat 35) & \Sexpr{x4} & \Sexpr{n4} & [\Sexpr{data4[7, 5]}, \Sexpr{data4[7, 6]}] &\Sexpr{data4[7, 6] - data4[7, 5]} \\\hline
		\end{tabular}
	\end{center}
	\caption{Uzyskane wyniki}
	\label{tab:tabela3}
\end{sidewaystable}
\begin{sidewaystable}
	\begin{center}
		\begin{tabular}{|c|c|c|c|c|}
			\hline
			\multicolumn{5}{|c|}{Przedziały ufności Profile} \\\hline
			Lek & Liczba sukcesów & Liczba prób & Przedział ufności & Długość przedziału \\\hline
			Ibuprofen & \Sexpr{x1} & \Sexpr{n1} & [\Sexpr{data1[8, 5]}, \Sexpr{data1[8, 6]}] &\Sexpr{data1[8, 6] - data1[8, 5]} \\\hline
			Ibuprofen (do lat 35) & \Sexpr{x2} & \Sexpr{n2} & [\Sexpr{data2[8, 5]}, \Sexpr{data2[8, 6]}] &\Sexpr{data2[8, 6] - data2[8, 5]} \\\hline
			Apap & \Sexpr{x3} & \Sexpr{n3} & [\Sexpr{data3[8, 5]}, \Sexpr{data3[8, 6]}] &\Sexpr{data3[8, 6] - data3[8, 5]} \\\hline
			Apap (do lat 35) & \Sexpr{x4} & \Sexpr{n4} & [\Sexpr{data4[8, 5]}, \Sexpr{data4[8, 6]}] &\Sexpr{data4[8, 6] - data4[8, 5]} \\\hline
			\multicolumn{5}{|c|}{Przedziały ufności Lrt} \\\hline
			Ibuprofen & \Sexpr{x1} & \Sexpr{n1} & [\Sexpr{data1[9, 5]}, \Sexpr{data1[9, 6]}] &\Sexpr{data1[9, 6] - data1[9, 5]} \\\hline
			Ibuprofen (do lat 35) & \Sexpr{x2} & \Sexpr{n2} & [\Sexpr{data2[9, 5]}, \Sexpr{data2[9, 6]}] &\Sexpr{data2[9, 6] - data2[9, 5]} \\\hline
			Apap & \Sexpr{x3} & \Sexpr{n3} & [\Sexpr{data3[9, 5]}, \Sexpr{data3[9, 6]}] &\Sexpr{data3[9, 6] - data3[9, 5]} \\\hline
			Apap (do lat 35) & \Sexpr{x4} & \Sexpr{n4} & [\Sexpr{data4[9, 5]}, \Sexpr{data4[9, 6]}] &\Sexpr{data4[9, 6] - data4[9, 5]} \\\hline
			\multicolumn{5}{|c|}{Przedziały ufności prop.test} \\\hline
			Ibuprofen & \Sexpr{x1} & \Sexpr{n1} & [\Sexpr{data1[10, 5]}, \Sexpr{data1[10, 6]}] &\Sexpr{data1[10, 6] - data1[10, 5]} \\\hline
			Ibuprofen (do lat 35) & \Sexpr{x2} & \Sexpr{n2} & [\Sexpr{data2[10, 5]}, \Sexpr{data2[10, 6]}] &\Sexpr{data2[10, 6] - data2[10, 5]} \\\hline
			Apap & \Sexpr{x3} & \Sexpr{n3} & [\Sexpr{data3[10, 5]}, \Sexpr{data3[10, 6]}] &\Sexpr{data3[10, 6] - data3[10, 5]} \\\hline
			Apap (do lat 35) & \Sexpr{x4} & \Sexpr{n4} & [\Sexpr{data4[10, 5]}, \Sexpr{data4[10, 6]}] &\Sexpr{data4[10, 6] - data4[10, 5]} \\\hline
			\multicolumn{5}{|c|}{Przedziały ufności Wilsona} \\\hline
			Ibuprofen & \Sexpr{x1} & \Sexpr{n1} & [\Sexpr{data1[11, 5]}, \Sexpr{data1[11, 6]}] &\Sexpr{data1[11, 6] - data1[1, 5]} \\\hline
			Ibuprofen (do lat 35) & \Sexpr{x2} & \Sexpr{n2} & [\Sexpr{data2[11, 5]}, \Sexpr{data2[11, 6]}] &\Sexpr{data2[11, 6] - data2[11, 5]} \\\hline
			Apap & \Sexpr{x3} & \Sexpr{n3} & [\Sexpr{data3[11, 5]}, \Sexpr{data3[11, 6]}] &\Sexpr{data3[11, 6] - data3[11, 5]} \\\hline
			Apap (do lat 35) & \Sexpr{x4} & \Sexpr{n4} & [\Sexpr{data4[11, 5]}, \Sexpr{data4[11, 6]}] &\Sexpr{data4[11, 6] - data4[11, 5]} \\\hline
		\end{tabular}
	\end{center}
	\caption{Uzyskane wyniki}
	\label{tab:tabela4}
>>>>>>> d4ea8b7876c9f168be9eb784204a7e33196481cf
\end{sidewaystable}
\newpage
Po porównaniu danych przedziałów ufności wyznaczonych różnymi metodami, 
widać, że przedziały ufności Agrestiego-Coulla i Walda, gdy liczba sukcesów jest równa zero,
wskazują niepokąjące wyniki. 
Pierwsza metoda wyznacza przedział ufności obejmujący wartości ujemne,
 zaś w drugim przypadku przedział ufności ma zerową długość.

Przypuszczam, że w przypadku zerowej liczby sukcesów, metody Agrestiego-Coulla i Walda nie działają poprawnie.
Przedziały ufności uzyskane pozostałymi metodami mają w ogólności zbliżoną długość, co wynika ze  stosunkowo duzych prób \(n\).
Przedziały ufności wyznaczone metodą Cloppera-Pearsona oraz prop.test mają największą długość. 
Najkrótsze długości przedziałów uzyskujemy stosując metodę Bayesa. 
Natomiast spośród trzech wyżej analizowanych metod, 
najlepszym wyborem wydaje się być test Agrestiego-Coulla, który ma najkrótsze przedziały ufności.  Jednak nie sprawdza się on przy skrajnych małej liczbie sukcesów, dając ujemną dolną granicę prawdopodobieństwa \(p\), co potwierdza wcześniejsze wnioski.
Dla skrajnych przypadków, spośród trzech badanych metod, najlepiej działa metoda Cloppera-Pearsona.

\subsection{Zadanie dodatkowe}
W tym zadaniu należało wyznaczyć granice punktowo asymptotycznego przedziału ufności, dla prawdopodobieństwa sukcesu, bazując na przekształceniu \emph{logit}, \emph{probit} albo \emph{cloglog}. Następnie dla wysymulowanych danych wyznaczyć realizację wyznaczonego przedziału i porównać z odpowiednią realizacją uzyskaną z funkcji \emph{binom.confint}.
\noindent Wybrałem metodę delta, bazującą na przedziale typu \emph{logit}, gdzie funkcja \(g\) jest równa \(g(p)=\ln\frac{p}{1-p}\).

Korzystając z wykładu, wiemy że w przypadku estymacji prawdopodobieństwa sukcesu \(p\), estymator największej wiarogodności \(\hat{p}\) jest postaci:
\begin{equation}
	\hat p(\mathbf{X})=\frac{1}{n}\displaystyle{\sum_{i=1}^n{X_i}=\overline{X}}
\end{equation}
oraz
\begin{equation}
	\sqrt{n}\frac{\overline X-p}{\sqrt{p(1-p)}}
\end{equation}
dąży, gdy \(n\rightarrow\infty\) według rozkładu do \(\mathcal{N}(0, 1)\). Wiemy na tej podstawie, że:
\begin{equation}
	\sqrt n(\hat p(\mathbf X) - p)
\end{equation}
dąży do rozkładu \(\mathcal N(0, p(1-p))\). Na tej podstawie, korzystając z wykładu, wiemy że:
\begin{equation}
	\sqrt n[g(\hat p(\mathbf X)) - g(p)]
\end{equation}
dąży do rozkładu \(\mathcal N(0, [g'(p)]^2p(1-p))\), gdzie funkcja \(g\), w typie \emph{logit}, to \(g(p)=\ln\frac{p}{1-p}\).

W następnym kroku, na podstawie funkcji centralnej asymptotycznie:
\begin{equation}
	Q_n(\mathbf X, p)=\frac{\sqrt n [g(\hat p(\mathbf X)) - g(p)]}{g'(p)\sqrt{p(1-p)}}
\end{equation}
konstruujemy przedział ufności dla parametru \(g(p)\):
\begin{equation}
z\left(\frac{\alpha}{2}\right)<\frac{\sqrt n [g(\hat p(\mathbf X)) - g(p)]}{g'(p)\sqrt{p(1-p)}}<z\left(1-\frac{\alpha}{2}\right)
\end{equation}
Wyznaczamy przedział dla \(g(p)\):
\begin{multline}
	-\frac{z\left(\frac{\alpha}{2}\right)g'(p)\sqrt{p(1-p)}}{\sqrt n} + g(\hat p(\mathbf X))> \\ > g(p) > \\ > -\frac{z\left(1-\frac{\alpha}{2}\right)g'(p)\sqrt{p(1-p)}}{\sqrt n} + g(\hat p(\mathbf X))
\end{multline}
Teraz "odwracamy" aby uzyskać przedział ufności dla \(p\). Dostajemy ostatecznie:
\begin{multline}
	g^{-1}\left(-\frac{z\left(1-\frac{\alpha}{2}\right)g'(p)\sqrt{p(1-p)}}{\sqrt n} + g(\hat p(\mathbf X))\right) < \\ < p < \\ < g^{-1}\left(-\frac{z\left(\frac{\alpha}{2}\right)g'(p)\sqrt{p(1-p)}}{\sqrt n} + g(\hat p(\mathbf X))\right)
\end{multline}
Przed sprawdzeniem poprawności wyznaczonego przedziału, musiałem wyznaczyć \(g'(p)\) oraz \(g^{-1}(p)\):
\begin{gather}
	g'(p)=\frac{1}{p-p^2}\\
	g^{-1}(p)=\frac{\exp(x)}{\exp(x)+1}
\end{gather}
Sprawdźmy teraz poprawność naszych przekształceń, przeprowadzając symulacje.
Jako prawdopodobieństwo sukcesu \(p\) przyjąłem \(p=0.3\), liczbę prób \(n=50\) oraz poziom istotności \(\alpha=0.05\).
\noindent Na początku wprowadźmy funkcję \(g\), funkcję liczącą pochodną funkcji \(g\) i funkcję liczącą funkcję odwrotną \(g\).
<<cache=F>>=
g <- function(x){
log(x/(1-x))
}
g.derivative <- function(x){
1/(x-x^2)
}
g.inv <- function(x){
exp(x)/(exp(x) + 1)
}
@
Teraz wysymulujmy próbę i wyznaczmy przedział ufności, korzystając z funkcji \verb|binom.confint|:
<<cache=F>>=
p <- 0.3
n <- 50
alfa <- 0.05
X <- rbinom(n, 1, p)

przedzial <- binom.confint(sum(X), n, methods="logit")
c(mean(przedzial$lower), mean(przedzial$upper))
@
A korzystając z naszych obliczeń, uzyskałem następujące wyniki:
<<cache=F>>=
Tl <- g.inv(- (qnorm(1-alfa/2)*g.derivative(p)
		*sqrt(p*(1-p)))/(sqrt(n)) + g(mean(X)))

Tu <- g.inv(- (qnorm(alfa/2)*g.derivative(p)
		*sqrt(p*(1-p)))/(sqrt(n)) + g(mean(X)))
c(Tl, Tu)
@
Porównując uzyskane wyniki wyznaczone z funkcji \verb|binom.confint| i uzyskane z naszych przekształceń, możemy powiedzieć, że uzyskany przez nas przedział został wyznaczony poprawnie.
\end{document}
